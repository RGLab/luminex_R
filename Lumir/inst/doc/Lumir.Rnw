%\VignetteIndexEntry{The Lumir users guide}
%\VignetteDepends{Lumir}
%\VignetteKeywords{Luminex multiplex assay analysis}
%\VignettePackage{Lumir}
\documentclass[11pt]{article}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{underscore}
\usepackage[hmargin=2cm, vmargin=3cm]{geometry}
\SweaveOpts{keep.source=FALSE}

\title{The Lumir User Guide}
\author{Renan Sauteraud\footnote{rsautera@fhcrc.org}}

\begin{document}
\maketitle

\tableofcontents

%\newpage

\section{Introduction}
\subsection{Technology}
Luminex \htmladdnormallink{xMAP}{http://www.luminexcorp.com/TechnologiesScience/xMAPTechnology/} technology is a multiplex assay using flow cytometry to concurrently measure up to 500 analytes in a single reaction volume.

\subsection{Lumir}
\texttt{Lumir} is an R package that provides data structure and functions to read, store and analyze Luminex xMAP experiment.

As with any R package, it should first be loaded in the session
<<loading-package>>=
library(Lumir)
@


\section{Softwares}
Even though Luminex is the company delivering the beads, a wide range of \htmladdnormallink{partners}{http://www.luminexcorp.com/Partners/} offer customizable kits and solutions for acquisition and/or analysis of the data. 
While the technology is identical, the output depends greatly on the software used for the acquisition. In its current version, \texttt{Lumir} can read the data from three different vendors:

\subsection{Luminex}
Luminex's own acquisition software xPONENT produces one csv file per well. These files contain the raw bead level information: bead id, fluorescence measured as well as the fluorescences used to map the bead. \texttt{Lumir} can read data from xPONENT versions 1.x and 3.x.

\subsection{MiraiBio}
MiraiBio also developped a set of tools for the acquisition and analysis of Luminex xMAP platform. The acquisition software `MasterPlex CT' currently in version 1.2 creates one file per well. These binary files with a .lxb extension are based on the format FCS 3.0 and contain the bead level information. Along with these files comes a summary in xml format with a .lxd extension. It contains some information regarding the setup used for the experiment, the matching of the bead id with the analyte name and some basic calculations such as the MFI or the bead count in each well for each analyte.

\subsection{BIO-RAD}
Bio-Plex Manager Software yields files with a proprietary format. However, it allows the user to exports the results in XML files that can be processed by \texttt{Lumir}. The output is a single XML file per experiment gathering all informations available.


\section{Requirements}
In order to read the data into R, the package require the data to be organized in a specific file tree.

\subsection{Folders architecture}
The experiment should be located in a folder (root) with the raw bead level files for each plate in a subfolder named after the plate name or ID. The mapping files should be placed at the root.

\subsection{Analyte mapping file}
In the raw data, the beads are referenced using a unique ID that is specific to a kit and a vendor. In order to use the actual analyte name, the package requires a file that will map each ID to a name. It should contain two columns \textbf{analyte} and \textbf{bid}.
If this file is not submitted by the user, \texttt{Lumir} will still be able to read the data but will display the bead ID instead of the actual name.
Alternately, with Bio-Plex data, the reading function will look for the .lxd file and attempt to extract this information.

\subsection{Phenotype mapping file}
This user provided file should contain information to match a sample (defined by a 'plate', a 'filename' and a 'well') and its phenotype information, including a 'group_name' a 'sample_type' (standard, case or control) as well as complementary details like standards 'expected_concentration', or cases matching 'control_idx'.
The package can still read the data and format it into a \texttt{blum}. However, this information is critical and the user will be asked to add it prior to any analysis such as standard curve fitting.

The minimum requirements for the mapping file are the three columns \textbf{plate}, \textbf{filename} and \textbf{well}. If no file is provided, the reading function will try to guess these informations based on the structure of the experiment folder. Additional information regarding the phenotype can be passed in the form of additional columns and should be provided in order to run any analysis such as standard curve fitting.
It is recommended to include the following columns:\\
A \textbf{group_name} and a \textbf{sample_type} (standard, case or control) as well as complementary details like the standards expected \textbf{concentration}, or the case's matching \textbf{control_idx}.


Additional optional info but if not provided, no analysis can be done.
If nothing is provided, we can still guess

An example of each mapping file is provided in the inst folder.
<<analyte.mapping.file>>=
path<-system.file("extdata",package="Lumir")
analyte<-read.csv(file.path(path, "analyte.csv"))
head(analyte)
phenotype<-read.csv(file.path(path, "phenotype.csv"))
head(phenotype,2)
@


\section{Data structure}
\texttt{Lumir} uses two classes to store different level of information.

\subsection{blum}
\texttt{blum} objects store the bead level information: bead id, the two fluorescence levels used for the bead characterization and the measured fluorescence for the analyte.

The reading function \texttt{read.experiment} only argument path takes the pathname of the root folder of an experiment and returns a \texttt{blum} object.
%<<read.experiment>>=
%blum<-read.experiment(path=path)
%@

\subsection{bsum}
\texttt{bSummarize} is used to create a \texttt{bsum}. It calculates the MFI associated with each analyte in each well and uses the given formula to fit the standard curves based on the standard wells.
%<<bSummarize>>=
%blum<-bSummarize(bama)
%@






\end{document}
